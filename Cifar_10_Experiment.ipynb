{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18acb0f",
   "metadata": {},
   "source": [
    "<h1> Experiment 1 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Pre-training the encoder using SimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from SimCLR_data_util import preprocess_for_train\n",
    "from resnet_small import ResNet18\n",
    "from tensorflow.keras.layers import Dense\n",
    "from SimCLR import SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.6.0'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cifar_10 import get_unsupervised_dataset\n",
    "dataset = get_unsupervised_dataset(batch_size=64)          # increase batch size if GPU memory available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations \n",
    "Build the random augmentation layer. In this case, the augmentations are based on a composition of randomly applied crops, collor jitter, reflection, gaussian blur, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAugmentation(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self, x):\n",
    "        augment_image = lambda im: preprocess_for_train(im, 32, 32)\n",
    "        return tf.map_fn(augment_image, x)\n",
    "\n",
    "augmentation = MyAugmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the original compared to the augmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/ayesha/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\nWARNING:tensorflow:From /home/ayesha/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /home/ayesha/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fab2f1ced30>"
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"184.681321pt\" version=\"1.1\" viewBox=\"0 0 368.925 184.681321\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-10-19T18:24:11.320127</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 184.681321 \nL 368.925 184.681321 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 160.803196 \nL 179.106818 160.803196 \nL 179.106818 8.621378 \nL 26.925 8.621378 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pc08d54cb33)\">\n    <image height=\"153\" id=\"image88ea868c3d\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"26.925\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAJkAAACZCAYAAAA8XJi6AAASBklEQVR4nO1dTXMcR3Kt7q7ume75wAADEARBCvwStStR0mq93nDsOhQbYcfGhi8++eo/sT/Ev8O3jT35YssOr215Zcqi5DUpECRBEgAxGGCm57O/u/ec9TIcPqhCl3y3zqjp6a5JFF5mvcp0fvN3v26UgWR2YZpUp5eR67B1CWP6Qwdsg5022JRbksvVuoYh8SRE26UHtmSlwVaVATU0LoypS/zONEnBFgT0Xp7GZ1ikeK9kifdqNznYei4dN13PYcxxge/YcuBnUx2/BbZ1Qr/z5HKBn+t0wPYXn34Mto8e3ifXn/3T5zDm5GwJNpx9geA7hjiZwDrEyQTWIU4msA7tFUjg/fy/wNZyKaELdAFjyjWS9elb9OPlihL/OMYHm14FjA3HeTWSVk9RAlwWJYxRGKOoukYy7Rh/h572YUyp8R0bvJUqanyOWUWJeJKsYYxf4ndmaQI2L4zAFs/puBdHOInnZ/idNwdgUv02Hff7z7+EMXN8LFnJBPYhTiawDnEygXWIkwmsQ988QGPWx2x11aakNSvRP1eY7AWSr5RSy3n0f14rpdRyWYGtSNEWBrij4PuUKHseQ+gZsp6mmJFvjGCgYoKITgsz8pq5f10hgfdbO/QZnAmM8SZMlr6Lc9bfGoKtd40+29zFz6XZG7AFHdzZOJ+dk+snr05hTOX1wCYrmcA6xMkE1iFOJrAO3e1iUjW7RHK1XFB/nCfIQ+Ir5HLzKY5TFU3adtq7MGQjQmXDyovBtlhjcrFq6P270QaMyRq8f44mVWSUBzpMltWp8YPdLnJFrXEu8oTO/zzGxGgQ4r16gz7YPB95VNenSe13byNvu76Fie9PfvwAbIvVihpqXKMulyuwyUomsA5xMoF1iJMJrEOcTGAdukwxuZjOMSk5mVNSOV2h+uFyhKS4yFHu0O1SopwolHvXGI+oumLI+hqf3w/p81cVkmnPxcRowBDnMqfEnxFXKIdJCHttVKQUJc5rklNZe6eHydJuF+facXF9cBxGWlLRiYwUTuxgG++/2cUgZXtri1z/5S9+AGO++GYENlnJBNYhTiawDnEygXWIkwmsQ8+nSATzDMnn9IJS3tEYKXBe4bm//0/mOwiQcHsB+n+RIVmvmWx4WszIdTtiMubdTbCNLlABkfmU+NcNE8j0cb4aJnKZz2dg0z59z+0hPlfg4Vxk3PYEs6OwyqiCI0sxCCpWeP/jo2OwPfwJPXf56afv43Nl6BeykgmsQ5xMYB3iZALrECcTWId+/Qaz0CdPUbKTVJSQtkOU2bZclEczXFR1DOlNFKIUh5NMbw22wDaZoCwpTgfk+uC9ezDm5OQcbBvXb4Jtr0WDjavxGL9vgmdXixzn0MX4RmUrOv/LJRZcaYcDtPVQ6lOWGGxULRogVEzGP0F1tzp6cwa2rZvUB/Zu7MOY4c5LsMlKJrAOcTKBdYiTCaxDj8aMzDlFia7Xpjv1XOE0z0cC5vnIrbTBtxqGJ4Qd5F9BiMleFcRg+smPf0aur91CTta7wfCoNSZLl2PKTS7OT2BMkqDkeGOjy9iQR1WGSuLw+TGM+fLpIdjcFs5/fxeTznce0u9sXYMhKp0gf7yY4lz89+E35PrjAH/vrT1MJstKJrAOcTKBdYiTCaxDnExgHTpnqkAHLSTYjUOThm6FpC+KMEG7rpBU5gWtlKYZZUCLqTI9Ygq/9bZ2wBYFNIE6fnOEY0KUR//7F/8GtnVMz3X6AaowOl2cryjC+zfMmc3G+Dvf278BY1KXqQQeo+w8Yc48jg1Sv7/HPNcefm7qx2BbpTQYGMY49/ffvw82WckE1iFOJrAOcTKBdYiTCaxD100GxjRDgt0OaYZ5zbSIWeV4frK3g+Twyijo0g6QjF7fwCIstcJgIIow853NqYy6rvAdv32GKgy3xPcOHBoYcQVXukxBOk5xkVdI1gsj8OKKsjy4iXNY38AAZJ6jIiXX9J3SGN+xCFGJ02XOXfrGuc7VAovdhPfeA5usZALrECcTWIc4mcA6xMkE1qFdlzk/WaKMWhnVritmTKEYyUuAGezt/Tvkemv3Dozp7d3C52KkOJMLlPueH70m1+/ceQfGXLuGZDoeYbGQ2mhVE2rM7jsaSfiK2cVomMAlN85xOgrPlnZDTmqNBL4bboOtMiKQ07MXMEZ1UJ7TYyp6t2tqW1/ie19eYDAgK5nAOsTJBNYhTiawDnEygXVozs9cjSW3ayPb6zBSnJaD91rMpmD767/9G3K9d/8TGPPiJWbkp2fPwRafPgXbckXPLpY1BimrFM8VnDOkdTigOwoVU81wdwfPROQjfP4rphlkb0hF97ff/RDG3LrzI7Atl3hYsq0xiPv60e/I9eETDM5CpmhN3WIK2RhBz3iNZ0RrT85dCr4HiJMJrEOcTGAd2nWQf3ESgsZoree7mKxrOJVBhmqNrx49ItdbBw9hzPs/Qp426iNPuHz2CGzeJj2zees+Fms7WzDJZA97ai+NJHTK9Ft028z5wyEmRmcJ8rSoR89n3mISxw8+/ABsiik4OHnzBGz/m1FlzFAjj3JyTBynM5TlL43EcRMyLRhdPC8rK5nAOsTJBNYhTiawDnEygXXoFpOIW2dI4CsjoRlGGDB4TMBQLpH4//bvf0uu2yEWn/v5r/4KbMN3sHBKVSP5HHRoUb2d2ygJjjQS1Ewhmc6MYirzeQxjLk9fgy1eoaR5bw/VJvsHtJBcv4sJ1ZPXGNxc38WkbX/AnP9s0/ttMmS9ZhQ1TMFwtWFU4Y6GOKjD1MSRlUxgHeJkAusQJxNYhziZwDp0wWTpN5mei0GHFlNpa5QJL5g+mc+vMJu8sUGVDc+//AcYc7CP/v/g01+Bze/hucv1yStyPT78CsYEOxhEfPDgXbB5hjQ5yZGYj87egG06woqMVcE0se9R8vz1IRaHCfHnUMNtlKenOcrTyza9f3SAFavzBtUhvoPvGRiVwDkJ/ugM1SGykgmsQ5xMYB3iZALrECcTWId2GRl12GKaqNeUtHoYL6iqRnnI0TnKr7cNGYx+jsT58e8+A1tvF89wHtxDGc+//getmLjT/wbGtK+j1Hpw8BHYdoeUYHeHuFOwsYOyniJhdieYQjZHR1Q+fvkCif/P/uynYBvu4v1HNe6uOEZZ+ibHM5aei/LxKsciNYnx/LNxDGOyBQaEspIJrEOcTGAd4mQC6xAnE1iHZvq2K89H8tYoOrBUyPydkPkc48aTmAYROsHg48vPsZ/QcO9zsD348OdgyzSV+rw4wR6VD3dRXnR+geP2P6LSmPYAJU4RU61yPWFKoGd4PuDePg0ktjf+HMYMdnAnQiksZ9/vYeMkc5Ph8hjPXTpMCfe6wGy+09Dfya8GMMYLUP4jK5nAOsTJBNYhTiawDl3hZrvSIfZqrE1yVeH/bI/5P76JNE2FEeV3gw7ynOkUzwd+8RkmaKMA+dzHP6WtV54+Ri5XMRW39+9igrPIYvq5M+zNnWfI5bwGE9PJJSaA65zW5NjewmRvvML6EtnLGGxJ/Bbvb0yjlyNncpi+lb6H649rmAqm0J/mPgcWgeA7hjiZwDrEyQTWIU4msA7dG+AOfLlEMr00zk86FSoKSiYYiLobYJvMKBtNC1QPeCUWqbs4w+b0p1//C9h+8UuqzKhXGFgsywnY7jOJ1tHzx+Q6LJHkV4ppAbRCm8sUFc8rGiC8vcAznKsMo6fZWwyMFldM4cARDTaCFgY8KaO4cJmHDT0aIHgKgxuXSeTLSiawDnEygXWIkwmsQ5xMYB06jlEZ0CR4ds5s0q493CrY2EKSf1Ahmc5f0nOR2sd77dxESXM6QtJ9evoKbPEZJbcFUySl3cPA4uTx78F2MaatcAYDPOfp1kh2Axff++34FJ9jg45bMRLt09f4G706ZHYemH6XrYiqNRqmn6bvoRTHU2jLjKqZjIBHFTnOq6xkAusQJxNYhziZwDrEyQTWob0Gs/uOh+RQGXLr1RIJarrAzHHbR2nJHaNx+3yNgcYOc8Zy7SHpPh1hWfF//Odn9HMpUtR9Rp5zwZz/nBpte8IB9slcXMVgu3V9D2zxCqXPd39Adyd2NvG9nQKf6+gPeD4znuM83h7SXpkVI0EqmLZArotzVhm6sIY5Z+ugO8lKJrAPcTKBdYiTCaxDh21MJDoe7tSb/6Ed5ixdnWIRPM2k7KI2TRBubiHXarXRlmjkAK8uMZE7z2hCkOm8ow4vHoPtvXtYIM7NKF8pFyihns+x3se3M+RfJcMpxxPKH++9i21vXr5G3jli5OkB08GoyOlzlBWjuGBaT3I25VOunjNKGc20apSVTGAd4mQC6xAnE1iHOJnAOrSqkbw1BdoclwYIGdPDe80kG11Gku0Ysl3HZ3pnFhhEdJheLNE2FnV78ZYmWpsae7G0mR6PV09QJXHdqPb3ySbeq5/j82cBKlKmTDuhy1PaV/1/Dv8AY9Y5Jr5Xa5zXG3sYWDgOPUPLqKNV7TC9PxlSb4ZYNViUaphkr6xkAusQJxNYhziZwDrEyQTWoaeXqEZIJkiAtdF7pWRanpQ5ElvNtE8x5b4u87kl01B+sNkH2w/v7oItnlBSfzll7l+iLV9z8mX6nn/yp5iR73uYHf/PK9w1eXJ8AbZRTDP3HAlvmErjboWZ9YCRVje+8WzM71Ew81/XaEsNaXXAFFcJGCm3rGQC6xAnE1iHOJnAOsTJBNahLyYoXdE5amM6bUogu0yje585iJczOpvIN1qxNEhGHQez+2XKFGZh/kzu3qRFZOoKC7WMF5hFr0okznOX6okvSqw6HexgZcpnL1+A7XiCBVHKmu5sbG3g/X94/TbYVmOU7Oz2MZ0/aNEfZZ7i52Yz3P1IMsz4l4b8eu8GSsWPx9LvUvA9QJxMYB3iZALrECcTWIeeMAS4z5Qt14WRAWbkJwGjC/cZN45jqok3W+oopVQQolSm08ZgYD5DUt812u/cu433ao+R2C4zfG/XUK785tFXMEYzL/n0Cgl2xpxx9Q1NfFnjXPSYs55NgjsDXOEa5VFSn6a4q5GneK91wsi9NJ3/Z69wt2g0ZypM4lMJBN8txMkE1iFOJrAOfTZGyfTCx//HN7YpVwhCrgQa2hoH/dgszLbOUGp9tcCkXsFIe01ZuFJKzQxlg9tCrniwj7LtqkLOtE4ot8oqfNbSQcXF1hB5oG8SPKVU30hqFw4mhL/6Fs+IvrN9H2xOhNLwmcGtEkYC3jBVrDNGgj++pPN6/AbPflYew2vBIhB8xxAnE1iHOJnAOsTJBNahxzEmz5YKd+W3ulR+XQdIuJcrRtnAfGljkNuiQl9vmCJsHvOd2kGy63hGlWamEXqP6XdZMf06lUcJ8Jr5uzSTv0optb2JZyA9pj1Ov0cTnEFvAGMSpoVO5GEAkueYHE2NIjgOo+XuMv1GSybIagxS32aS42kh/S4F3wPEyQTWIU4msA5xMoF1aK4IyLJgJLoGqdc1Es+wxfQ61OjHlVFtOVnjMzBdY1TJnJVUAZJPz+jpqJlM+7VrA7At5rj7ERjlCyOm0AynIolamPkucpyL2qhYWTFydV+jumKdY7Y9Y/pWBsZuR4dpau8xGvZOJwLbNSMuKpnq16cjkV8LvgeIkwmsQ5xMYB3iZALr0GmDRHC6wMz34SmVTN/dRSnLfohnBodbaHMMyXGLyWinptxbKZXkjLyYCVIqRQOQssQxkwXuavBxBc3cM8l9tirhMsXdD58h3bWRRc+ZypTtAHc1EkZy5Hr4cJXJzZmWRlEXf8tihfOTGedxXWaN2ujgs8pKJrAOcTKBdYiTCaxDJyXynBn+u1evjCNerprBGN/B5FwUoR+3W9QWMMlG38f/7Wumrc46Qe5TGEREM4XZZhNMGpYlPr/nUm7SanHPxbS4YZLV29EQbFVFeU6RIX9UGSacK0ayXlVIKqOIckqHOZaXMPzLc/F387XBdRmJdq+P/E5WMoF1iJMJrEOcTGAd4mQC69AfvP8BGON4AraWoWTYDJCsR0PcuW9ClCF3BrRoXMAkEXUL5dFcInEyjcGWG8HM5oAhoxWS1owh3alReK8dIgnfYETm6wRrTvQHWL1bNfSzOUPoPYXz02bON/a6WIyv06Hz7zM94RPmO7nzsso1+l0ynyuZPqiykgmsQ5xMYB3iZALrECcTWMcfAfRsAZofH2buAAAAAElFTkSuQmCC\" y=\"-7.803196\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"me95fe7a03c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.302841\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.121591 175.401634)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.859659\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(70.497159 175.401634)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.416477\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <g transform=\"translate(118.053977 175.401634)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.973295\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <g transform=\"translate(165.610795 175.401634)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_5\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m37efb70797\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m37efb70797\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m37efb70797\" y=\"34.777628\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 38.576847)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m37efb70797\" y=\"58.556037\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 62.355256)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m37efb70797\" y=\"82.334446\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 86.133665)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m37efb70797\" y=\"106.112855\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 109.912074)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m37efb70797\" y=\"129.891264\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 133.690483)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m37efb70797\" y=\"153.669673\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 157.468892)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 160.803196 \nL 26.925 8.621378 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 179.106818 160.803196 \nL 179.106818 8.621378 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 160.803196 \nL 179.106818 160.803196 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 8.621378 \nL 179.106818 8.621378 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 209.543182 160.803196 \nL 361.725 160.803196 \nL 361.725 8.621378 \nL 209.543182 8.621378 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p4c28d25d6e)\">\n    <image height=\"153\" id=\"image7dff69edac\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\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\" y=\"-7.803196\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"211.921023\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0 -->\n      <g transform=\"translate(208.739773 175.401634)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"259.477841\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 10 -->\n      <g transform=\"translate(253.115341 175.401634)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"307.034659\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 20 -->\n      <g transform=\"translate(300.672159 175.401634)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"354.591477\" xlink:href=\"#me95fe7a03c\" y=\"160.803196\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 30 -->\n      <g transform=\"translate(348.228977 175.401634)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_8\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m37efb70797\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0 -->\n      <g transform=\"translate(196.180682 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m37efb70797\" y=\"34.777628\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 5 -->\n      <g transform=\"translate(196.180682 38.576847)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m37efb70797\" y=\"58.556037\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 10 -->\n      <g transform=\"translate(189.818182 62.355256)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m37efb70797\" y=\"82.334446\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 15 -->\n      <g transform=\"translate(189.818182 86.133665)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m37efb70797\" y=\"106.112855\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 20 -->\n      <g transform=\"translate(189.818182 109.912074)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m37efb70797\" y=\"129.891264\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 25 -->\n      <g transform=\"translate(189.818182 133.690483)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m37efb70797\" y=\"153.669673\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 30 -->\n      <g transform=\"translate(189.818182 157.468892)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 209.543182 160.803196 \nL 209.543182 8.621378 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 361.725 160.803196 \nL 361.725 8.621378 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 209.543182 160.803196 \nL 361.725 160.803196 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 209.543182 8.621378 \nL 361.725 8.621378 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc08d54cb33\">\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"26.925\" y=\"8.621378\"/>\n  </clipPath>\n  <clipPath id=\"p4c28d25d6e\">\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"209.543182\" y=\"8.621378\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "batch = next(iter(dataset))\n",
    "batch_augmented = augmentation(batch)\n",
    "fix, (axis1, axis2) = plt.subplots(1, 2)\n",
    "axis1.imshow(batch[0])\n",
    "axis2.imshow(batch_augmented[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder \n",
    "Build the encoder. We use a ResNet18 backbone, with the final layer removed, and passed through a dense layer onto 2048-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5a556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "    model = ResNet18(10)\n",
    "    encoder = tf.keras.Sequential(model.layers[:-1])\n",
    "    # encoder = tf.keras.Sequential([\n",
    "    #     encoder, \n",
    "    #     tf.keras.layers.ReLU(), \n",
    "    #     tf.keras.layers.Dense(2048)\n",
    "    # ])\n",
    "    return encoder\n",
    "\n",
    "encoder = get_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the encoder network: first, we must build the network by calling it on a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (64, 32, 32, 64)          1728      \n_________________________________________________________________\nbatch_normalization (BatchNo (64, 32, 32, 64)          256       \n_________________________________________________________________\nsequential_2 (Sequential)    (64, 32, 32, 64)          148480    \n_________________________________________________________________\nsequential_5 (Sequential)    (64, 16, 16, 128)         526848    \n_________________________________________________________________\nsequential_8 (Sequential)    (64, 8, 8, 256)           2102272   \n_________________________________________________________________\nsequential_11 (Sequential)   (64, 4, 4, 512)           8398848   \n_________________________________________________________________\nflatten (Flatten)            (64, 8192)                0         \n=================================================================\nTotal params: 11,178,432\nTrainable params: 11,168,832\nNon-trainable params: 9,600\n_________________________________________________________________\ninput shape: (64, 32, 32, 3)\noutput shape: (64, 8192)\n"
    }
   ],
   "source": [
    "batch = next(iter(dataset))\n",
    "output = encoder(batch)\n",
    "encoder.summary()\n",
    "print(f'input shape: {batch.shape}')\n",
    "print(f'output shape: {output.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the network maps images of size 32 x 32 x 3 to representations of 8192 dimensions. Our goal is to pretrain this encoder by learning good representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection head \n",
    "\n",
    "SimCLR requires a projection head which projects the high-dimensional representation onto a lower-dimensional embedding space. Here we use a simple multi-layer perceptron which maps from the 8192-dimensional representation space to a 265-dimensional embedding space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection_head():\n",
    "\n",
    "    projection_head = tf.keras.Sequential([\n",
    "        Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(256)\n",
    "    ])\n",
    "\n",
    "    return projection_head\n",
    "\n",
    "projection_head = get_projection_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (64, 1024)                8389632   \n_________________________________________________________________\ndropout (Dropout)            (64, 1024)                0         \n_________________________________________________________________\ndense_2 (Dense)              (64, 512)                 524800    \n_________________________________________________________________\ndropout_1 (Dropout)          (64, 512)                 0         \n_________________________________________________________________\ndense_3 (Dense)              (64, 256)                 131328    \n=================================================================\nTotal params: 9,045,760\nTrainable params: 9,045,760\nNon-trainable params: 0\n_________________________________________________________________\ninput shape: (64, 32, 32, 3)\noutput shape: (64, 256)\n"
    }
   ],
   "source": [
    "batch = next(iter(dataset))\n",
    "output = projection_head(encoder(batch))\n",
    "projection_head.summary()\n",
    "print(f'input shape: {batch.shape}')\n",
    "print(f'output shape: {output.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the SimCLR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_clr_model = SimCLR(encoder, augmentation, projection_head, temperature=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sim_clr\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nsequential_12 (Sequential)   (None, 8192)              11178432  \n_________________________________________________________________\nsequential_13 (Sequential)   (None, 256)               9045760   \n_________________________________________________________________\nmy_augmentation (MyAugmentat multiple                  0         \n_________________________________________________________________\nsim_clr_logits_from_embeddin multiple                  0         \n=================================================================\nTotal params: 20,224,192\nTrainable params: 20,214,592\nNon-trainable params: 9,600\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sim_clr_model(next(iter(dataset)))\n",
    "sim_clr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the unsupervised pre-training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[==============================] - 154s 657ms/step - SimCLR_loss: 0.1467 - SimCLR_accuracy: 0.9846\nEpoch 36/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.1420 - SimCLR_accuracy: 0.9863\nEpoch 37/200\n234/234 [==============================] - 153s 653ms/step - SimCLR_loss: 0.1387 - SimCLR_accuracy: 0.9868\nEpoch 38/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.1374 - SimCLR_accuracy: 0.9864\nEpoch 39/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.1381 - SimCLR_accuracy: 0.9861\nEpoch 40/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.1315 - SimCLR_accuracy: 0.9877\nEpoch 41/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.1327 - SimCLR_accuracy: 0.9872\nEpoch 42/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.1292 - SimCLR_accuracy: 0.9881\nEpoch 43/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.1266 - SimCLR_accuracy: 0.9886\nEpoch 44/200\n234/234 [==============================] - 161s 690ms/step - SimCLR_loss: 0.1239 - SimCLR_accuracy: 0.9887\nEpoch 45/200\n234/234 [==============================] - 209s 894ms/step - SimCLR_loss: 0.1232 - SimCLR_accuracy: 0.9893\nEpoch 46/200\n234/234 [==============================] - 176s 750ms/step - SimCLR_loss: 0.1200 - SimCLR_accuracy: 0.9894\nEpoch 47/200\n234/234 [==============================] - 156s 668ms/step - SimCLR_loss: 0.1168 - SimCLR_accuracy: 0.9902\nEpoch 48/200\n234/234 [==============================] - 210s 897ms/step - SimCLR_loss: 0.1189 - SimCLR_accuracy: 0.9899\nEpoch 49/200\n234/234 [==============================] - 212s 906ms/step - SimCLR_loss: 0.1156 - SimCLR_accuracy: 0.9905\nEpoch 50/200\n234/234 [==============================] - 212s 906ms/step - SimCLR_loss: 0.1153 - SimCLR_accuracy: 0.9901\nEpoch 51/200\n234/234 [==============================] - 213s 909ms/step - SimCLR_loss: 0.1101 - SimCLR_accuracy: 0.9905\nEpoch 52/200\n234/234 [==============================] - 174s 744ms/step - SimCLR_loss: 0.1075 - SimCLR_accuracy: 0.9912\nEpoch 53/200\n234/234 [==============================] - 151s 645ms/step - SimCLR_loss: 0.1093 - SimCLR_accuracy: 0.9913\nEpoch 54/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.1073 - SimCLR_accuracy: 0.9915\nEpoch 55/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.1069 - SimCLR_accuracy: 0.9914\nEpoch 56/200\n234/234 [==============================] - 152s 647ms/step - SimCLR_loss: 0.1043 - SimCLR_accuracy: 0.9919\nEpoch 57/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.1013 - SimCLR_accuracy: 0.9922\nEpoch 58/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.1027 - SimCLR_accuracy: 0.9918\nEpoch 59/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0984 - SimCLR_accuracy: 0.9925\nEpoch 60/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0970 - SimCLR_accuracy: 0.9925\nEpoch 61/200\n234/234 [==============================] - 153s 655ms/step - SimCLR_loss: 0.0976 - SimCLR_accuracy: 0.9926\nEpoch 62/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0988 - SimCLR_accuracy: 0.9924\nEpoch 63/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0984 - SimCLR_accuracy: 0.9925\nEpoch 64/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0924 - SimCLR_accuracy: 0.9933\nEpoch 65/200\n234/234 [==============================] - 153s 655ms/step - SimCLR_loss: 0.0912 - SimCLR_accuracy: 0.9938\nEpoch 66/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0929 - SimCLR_accuracy: 0.9931\nEpoch 67/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0899 - SimCLR_accuracy: 0.9938\nEpoch 68/200\n234/234 [==============================] - 154s 656ms/step - SimCLR_loss: 0.0872 - SimCLR_accuracy: 0.9943\nEpoch 69/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0879 - SimCLR_accuracy: 0.9939\nEpoch 70/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0876 - SimCLR_accuracy: 0.9945\nEpoch 71/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0864 - SimCLR_accuracy: 0.9942\nEpoch 72/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0864 - SimCLR_accuracy: 0.9940\nEpoch 73/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0870 - SimCLR_accuracy: 0.9940\nEpoch 74/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0827 - SimCLR_accuracy: 0.9947\nEpoch 75/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0840 - SimCLR_accuracy: 0.9946\nEpoch 76/200\n234/234 [==============================] - 154s 659ms/step - SimCLR_loss: 0.0819 - SimCLR_accuracy: 0.9949\nEpoch 77/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0846 - SimCLR_accuracy: 0.9940\nEpoch 78/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0841 - SimCLR_accuracy: 0.9942\nEpoch 79/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0802 - SimCLR_accuracy: 0.9948\nEpoch 80/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0804 - SimCLR_accuracy: 0.9951\nEpoch 81/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0793 - SimCLR_accuracy: 0.9952\nEpoch 82/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0790 - SimCLR_accuracy: 0.9951\nEpoch 83/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0782 - SimCLR_accuracy: 0.9948\nEpoch 84/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0770 - SimCLR_accuracy: 0.9954\nEpoch 85/200\n234/234 [==============================] - 152s 647ms/step - SimCLR_loss: 0.0770 - SimCLR_accuracy: 0.9951\nEpoch 86/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0762 - SimCLR_accuracy: 0.9953\nEpoch 87/200\n234/234 [==============================] - 152s 647ms/step - SimCLR_loss: 0.0736 - SimCLR_accuracy: 0.9959\nEpoch 88/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0768 - SimCLR_accuracy: 0.9952\nEpoch 89/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0730 - SimCLR_accuracy: 0.9958\nEpoch 90/200\n234/234 [==============================] - 153s 655ms/step - SimCLR_loss: 0.0754 - SimCLR_accuracy: 0.9953\nEpoch 91/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0725 - SimCLR_accuracy: 0.9959\nEpoch 92/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0736 - SimCLR_accuracy: 0.9957\nEpoch 93/200\n234/234 [==============================] - 153s 654ms/step - SimCLR_loss: 0.0731 - SimCLR_accuracy: 0.9955\nEpoch 94/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0708 - SimCLR_accuracy: 0.9957\nEpoch 95/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0726 - SimCLR_accuracy: 0.9955\nEpoch 96/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0713 - SimCLR_accuracy: 0.9958\nEpoch 97/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0709 - SimCLR_accuracy: 0.9958\nEpoch 98/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0675 - SimCLR_accuracy: 0.9964\nEpoch 99/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0686 - SimCLR_accuracy: 0.9962\nEpoch 100/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0666 - SimCLR_accuracy: 0.9965\nEpoch 101/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0670 - SimCLR_accuracy: 0.9965\nEpoch 102/200\n234/234 [==============================] - 151s 645ms/step - SimCLR_loss: 0.0662 - SimCLR_accuracy: 0.9963\nEpoch 103/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0686 - SimCLR_accuracy: 0.9962\nEpoch 104/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0657 - SimCLR_accuracy: 0.9964\nEpoch 105/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0665 - SimCLR_accuracy: 0.9962\nEpoch 106/200\n234/234 [==============================] - 152s 647ms/step - SimCLR_loss: 0.0656 - SimCLR_accuracy: 0.9963\nEpoch 107/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0634 - SimCLR_accuracy: 0.9968\nEpoch 108/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0632 - SimCLR_accuracy: 0.9967\nEpoch 109/200\n234/234 [==============================] - 152s 647ms/step - SimCLR_loss: 0.0628 - SimCLR_accuracy: 0.9968\nEpoch 110/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0618 - SimCLR_accuracy: 0.9969\nEpoch 111/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0636 - SimCLR_accuracy: 0.9965\nEpoch 112/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0616 - SimCLR_accuracy: 0.9969\nEpoch 113/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0615 - SimCLR_accuracy: 0.9970\nEpoch 114/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0610 - SimCLR_accuracy: 0.9967\nEpoch 115/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0608 - SimCLR_accuracy: 0.9971\nEpoch 116/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0593 - SimCLR_accuracy: 0.9970\nEpoch 117/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0608 - SimCLR_accuracy: 0.9968\nEpoch 118/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0618 - SimCLR_accuracy: 0.9967\nEpoch 119/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0601 - SimCLR_accuracy: 0.9971\nEpoch 120/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0579 - SimCLR_accuracy: 0.9973\nEpoch 121/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0591 - SimCLR_accuracy: 0.9971\nEpoch 122/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0576 - SimCLR_accuracy: 0.9974\nEpoch 123/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0583 - SimCLR_accuracy: 0.9973\nEpoch 124/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0585 - SimCLR_accuracy: 0.9970\nEpoch 125/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0572 - SimCLR_accuracy: 0.9974\nEpoch 126/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0590 - SimCLR_accuracy: 0.9969\nEpoch 127/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0559 - SimCLR_accuracy: 0.9973\nEpoch 128/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0581 - SimCLR_accuracy: 0.9973\nEpoch 129/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0565 - SimCLR_accuracy: 0.9973\nEpoch 130/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0560 - SimCLR_accuracy: 0.9974\nEpoch 131/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0565 - SimCLR_accuracy: 0.9974\nEpoch 132/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0552 - SimCLR_accuracy: 0.9973\nEpoch 133/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0554 - SimCLR_accuracy: 0.9974\nEpoch 134/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0528 - SimCLR_accuracy: 0.9978\nEpoch 135/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0536 - SimCLR_accuracy: 0.9976\nEpoch 136/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0540 - SimCLR_accuracy: 0.9979\nEpoch 137/200\n234/234 [==============================] - 152s 647ms/step - SimCLR_loss: 0.0530 - SimCLR_accuracy: 0.9975\nEpoch 138/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0539 - SimCLR_accuracy: 0.9975\nEpoch 139/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0531 - SimCLR_accuracy: 0.9975\nEpoch 140/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0551 - SimCLR_accuracy: 0.9971\nEpoch 141/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0533 - SimCLR_accuracy: 0.9975\nEpoch 142/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0526 - SimCLR_accuracy: 0.9974\nEpoch 143/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0525 - SimCLR_accuracy: 0.9976\nEpoch 144/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0546 - SimCLR_accuracy: 0.9973\nEpoch 145/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0518 - SimCLR_accuracy: 0.9978\nEpoch 146/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0506 - SimCLR_accuracy: 0.9980\nEpoch 147/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0521 - SimCLR_accuracy: 0.9976\nEpoch 148/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0514 - SimCLR_accuracy: 0.9978\nEpoch 149/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0518 - SimCLR_accuracy: 0.9976\nEpoch 150/200\n234/234 [==============================] - 153s 652ms/step - SimCLR_loss: 0.0500 - SimCLR_accuracy: 0.9978\nEpoch 151/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0525 - SimCLR_accuracy: 0.9976\nEpoch 152/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0505 - SimCLR_accuracy: 0.9977\nEpoch 153/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0506 - SimCLR_accuracy: 0.9976\nEpoch 154/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0495 - SimCLR_accuracy: 0.9980\nEpoch 155/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0490 - SimCLR_accuracy: 0.9978\nEpoch 156/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0496 - SimCLR_accuracy: 0.9978\nEpoch 157/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0481 - SimCLR_accuracy: 0.9980\nEpoch 158/200\n234/234 [==============================] - 153s 652ms/step - SimCLR_loss: 0.0469 - SimCLR_accuracy: 0.9979\nEpoch 159/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0482 - SimCLR_accuracy: 0.9980\nEpoch 160/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0472 - SimCLR_accuracy: 0.9980\nEpoch 161/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0470 - SimCLR_accuracy: 0.9981\nEpoch 162/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0478 - SimCLR_accuracy: 0.9979\nEpoch 163/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0470 - SimCLR_accuracy: 0.9981\nEpoch 164/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0472 - SimCLR_accuracy: 0.9978\nEpoch 165/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0465 - SimCLR_accuracy: 0.9981\nEpoch 166/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0465 - SimCLR_accuracy: 0.9980\nEpoch 167/200\n234/234 [==============================] - 154s 657ms/step - SimCLR_loss: 0.0450 - SimCLR_accuracy: 0.9983\nEpoch 168/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0453 - SimCLR_accuracy: 0.9981\nEpoch 169/200\n234/234 [==============================] - 153s 655ms/step - SimCLR_loss: 0.0442 - SimCLR_accuracy: 0.9983\nEpoch 170/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0436 - SimCLR_accuracy: 0.9983\nEpoch 171/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0427 - SimCLR_accuracy: 0.9984\nEpoch 172/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0434 - SimCLR_accuracy: 0.9983\nEpoch 173/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0443 - SimCLR_accuracy: 0.9981\nEpoch 174/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0430 - SimCLR_accuracy: 0.9984\nEpoch 175/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0418 - SimCLR_accuracy: 0.9984\nEpoch 176/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0421 - SimCLR_accuracy: 0.9984\nEpoch 177/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0414 - SimCLR_accuracy: 0.9984\nEpoch 178/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0429 - SimCLR_accuracy: 0.9981\nEpoch 179/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0423 - SimCLR_accuracy: 0.9983\nEpoch 180/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0416 - SimCLR_accuracy: 0.9983\nEpoch 181/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0410 - SimCLR_accuracy: 0.9985\nEpoch 182/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0401 - SimCLR_accuracy: 0.9985\nEpoch 183/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0398 - SimCLR_accuracy: 0.9984\nEpoch 184/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0399 - SimCLR_accuracy: 0.9985\nEpoch 185/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0409 - SimCLR_accuracy: 0.9983\nEpoch 186/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0403 - SimCLR_accuracy: 0.9986\nEpoch 187/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0391 - SimCLR_accuracy: 0.9987\nEpoch 188/200\n234/234 [==============================] - 152s 651ms/step - SimCLR_loss: 0.0388 - SimCLR_accuracy: 0.9985\nEpoch 189/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0389 - SimCLR_accuracy: 0.9986\nEpoch 190/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0371 - SimCLR_accuracy: 0.9989\nEpoch 191/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0379 - SimCLR_accuracy: 0.9988\nEpoch 192/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0372 - SimCLR_accuracy: 0.9986\nEpoch 193/200\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 0.0374 - SimCLR_accuracy: 0.9987\nEpoch 194/200\n234/234 [==============================] - 152s 649ms/step - SimCLR_loss: 0.0382 - SimCLR_accuracy: 0.9985\nEpoch 195/200\n234/234 [==============================] - 152s 650ms/step - SimCLR_loss: 0.0372 - SimCLR_accuracy: 0.9987\nEpoch 196/200\n234/234 [==============================] - 151s 646ms/step - SimCLR_loss: 0.0374 - SimCLR_accuracy: 0.9986\nEpoch 197/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0352 - SimCLR_accuracy: 0.9989\nEpoch 198/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0362 - SimCLR_accuracy: 0.9987\nEpoch 199/200\n234/234 [==============================] - 152s 647ms/step - SimCLR_loss: 0.0364 - SimCLR_accuracy: 0.9987\nEpoch 200/200\n234/234 [==============================] - 151s 647ms/step - SimCLR_loss: 0.0368 - SimCLR_accuracy: 0.9987\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fab2ed98a58>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "BATCH_SIZE = 256 \n",
    "EPOCHS = 200     \n",
    "LEARNING_RATE = 0.0003\n",
    "SAVE_DIRECTORY = './cifar_10_experiment'\n",
    "\n",
    "#sim_clr_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "sim_clr_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE, momentum=0.9))\n",
    "\n",
    "\n",
    "dataset = get_unsupervised_dataset(batch_size=BATCH_SIZE)  \n",
    "dataset = dataset.take(len(dataset)-1)\n",
    "\n",
    "sim_clr_model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_clr_model.save_weights(f'{SAVE_DIRECTORY}/simclr_weights/ckpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n234/234 [==============================] - 150s 627ms/step - SimCLR_loss: 0.0339 - SimCLR_accuracy: 0.9989\nEpoch 2/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0325 - SimCLR_accuracy: 0.9990\nEpoch 3/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0329 - SimCLR_accuracy: 0.9989\nEpoch 4/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0320 - SimCLR_accuracy: 0.9988\nEpoch 5/100\n234/234 [==============================] - 151s 643ms/step - SimCLR_loss: 0.0317 - SimCLR_accuracy: 0.9990\nEpoch 6/100\n234/234 [==============================] - 151s 644ms/step - SimCLR_loss: 0.0319 - SimCLR_accuracy: 0.9989\nEpoch 7/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0317 - SimCLR_accuracy: 0.9989\nEpoch 8/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0312 - SimCLR_accuracy: 0.9991\nEpoch 9/100\n234/234 [==============================] - 148s 635ms/step - SimCLR_loss: 0.0303 - SimCLR_accuracy: 0.9989\nEpoch 10/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0304 - SimCLR_accuracy: 0.9990\nEpoch 11/100\n234/234 [==============================] - 148s 631ms/step - SimCLR_loss: 0.0304 - SimCLR_accuracy: 0.9991\nEpoch 12/100\n234/234 [==============================] - 149s 637ms/step - SimCLR_loss: 0.0310 - SimCLR_accuracy: 0.9991\nEpoch 13/100\n234/234 [==============================] - 148s 631ms/step - SimCLR_loss: 0.0298 - SimCLR_accuracy: 0.9991\nEpoch 14/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 0.0306 - SimCLR_accuracy: 0.9990\nEpoch 15/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0304 - SimCLR_accuracy: 0.9991\nEpoch 16/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0305 - SimCLR_accuracy: 0.9991\nEpoch 17/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0301 - SimCLR_accuracy: 0.9989\nEpoch 18/100\n234/234 [==============================] - 149s 635ms/step - SimCLR_loss: 0.0294 - SimCLR_accuracy: 0.9990\nEpoch 19/100\n234/234 [==============================] - 148s 632ms/step - SimCLR_loss: 0.0289 - SimCLR_accuracy: 0.9992\nEpoch 20/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0293 - SimCLR_accuracy: 0.9988\nEpoch 21/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0284 - SimCLR_accuracy: 0.9993\nEpoch 22/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0285 - SimCLR_accuracy: 0.9992\nEpoch 23/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0283 - SimCLR_accuracy: 0.9992\nEpoch 24/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0279 - SimCLR_accuracy: 0.9992\nEpoch 25/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0280 - SimCLR_accuracy: 0.9992\nEpoch 26/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0277 - SimCLR_accuracy: 0.9992\nEpoch 27/100\n234/234 [==============================] - 149s 637ms/step - SimCLR_loss: 0.0282 - SimCLR_accuracy: 0.9992\nEpoch 28/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0279 - SimCLR_accuracy: 0.9991\nEpoch 29/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0266 - SimCLR_accuracy: 0.9994\nEpoch 30/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 0.0281 - SimCLR_accuracy: 0.9991\nEpoch 31/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0281 - SimCLR_accuracy: 0.9991\nEpoch 32/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0268 - SimCLR_accuracy: 0.9993\nEpoch 33/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0281 - SimCLR_accuracy: 0.9991\nEpoch 34/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0269 - SimCLR_accuracy: 0.9993\nEpoch 35/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0265 - SimCLR_accuracy: 0.9992\nEpoch 36/100\n234/234 [==============================] - 146s 626ms/step - SimCLR_loss: 0.0276 - SimCLR_accuracy: 0.9992\nEpoch 37/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0262 - SimCLR_accuracy: 0.9994\nEpoch 38/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0262 - SimCLR_accuracy: 0.9993\nEpoch 39/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0266 - SimCLR_accuracy: 0.9992\nEpoch 40/100\n234/234 [==============================] - 149s 635ms/step - SimCLR_loss: 0.0266 - SimCLR_accuracy: 0.9993\nEpoch 41/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0261 - SimCLR_accuracy: 0.9993\nEpoch 42/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0259 - SimCLR_accuracy: 0.9993\nEpoch 43/100\n234/234 [==============================] - 149s 639ms/step - SimCLR_loss: 0.0252 - SimCLR_accuracy: 0.9992\nEpoch 44/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0252 - SimCLR_accuracy: 0.9995\nEpoch 45/100\n234/234 [==============================] - 148s 635ms/step - SimCLR_loss: 0.0248 - SimCLR_accuracy: 0.9994\nEpoch 46/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0252 - SimCLR_accuracy: 0.9993\nEpoch 47/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0244 - SimCLR_accuracy: 0.9995\nEpoch 48/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 0.0253 - SimCLR_accuracy: 0.9993\nEpoch 49/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0249 - SimCLR_accuracy: 0.9994\nEpoch 50/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0254 - SimCLR_accuracy: 0.9992\nEpoch 51/100\n234/234 [==============================] - 148s 633ms/step - SimCLR_loss: 0.0248 - SimCLR_accuracy: 0.9995\nEpoch 52/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0242 - SimCLR_accuracy: 0.9994\nEpoch 53/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0248 - SimCLR_accuracy: 0.9992\nEpoch 54/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0240 - SimCLR_accuracy: 0.9995\nEpoch 55/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0235 - SimCLR_accuracy: 0.9994\nEpoch 56/100\n234/234 [==============================] - 149s 635ms/step - SimCLR_loss: 0.0245 - SimCLR_accuracy: 0.9995\nEpoch 57/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0242 - SimCLR_accuracy: 0.9994\nEpoch 58/100\n234/234 [==============================] - 146s 626ms/step - SimCLR_loss: 0.0233 - SimCLR_accuracy: 0.9995\nEpoch 59/100\n234/234 [==============================] - 148s 631ms/step - SimCLR_loss: 0.0245 - SimCLR_accuracy: 0.9993\nEpoch 60/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0237 - SimCLR_accuracy: 0.9994\nEpoch 61/100\n234/234 [==============================] - 149s 637ms/step - SimCLR_loss: 0.0232 - SimCLR_accuracy: 0.9995\nEpoch 62/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0233 - SimCLR_accuracy: 0.9995\nEpoch 63/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0227 - SimCLR_accuracy: 0.9995\nEpoch 64/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0229 - SimCLR_accuracy: 0.9994\nEpoch 65/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0232 - SimCLR_accuracy: 0.9994\nEpoch 66/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0234 - SimCLR_accuracy: 0.9994\nEpoch 67/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0227 - SimCLR_accuracy: 0.9994\nEpoch 68/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0223 - SimCLR_accuracy: 0.9994\nEpoch 69/100\n234/234 [==============================] - 147s 626ms/step - SimCLR_loss: 0.0222 - SimCLR_accuracy: 0.9995\nEpoch 70/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0217 - SimCLR_accuracy: 0.9995\nEpoch 71/100\n234/234 [==============================] - 148s 633ms/step - SimCLR_loss: 0.0218 - SimCLR_accuracy: 0.9995\nEpoch 72/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0223 - SimCLR_accuracy: 0.9995\nEpoch 73/100\n234/234 [==============================] - 147s 626ms/step - SimCLR_loss: 0.0219 - SimCLR_accuracy: 0.9995\nEpoch 74/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0220 - SimCLR_accuracy: 0.9995\nEpoch 75/100\n234/234 [==============================] - 148s 630ms/step - SimCLR_loss: 0.0215 - SimCLR_accuracy: 0.9996\nEpoch 76/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0222 - SimCLR_accuracy: 0.9994\nEpoch 77/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0220 - SimCLR_accuracy: 0.9994\nEpoch 78/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0215 - SimCLR_accuracy: 0.9996\nEpoch 79/100\n234/234 [==============================] - 150s 641ms/step - SimCLR_loss: 0.0218 - SimCLR_accuracy: 0.9995\nEpoch 80/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 0.0212 - SimCLR_accuracy: 0.9995\nEpoch 81/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 0.0203 - SimCLR_accuracy: 0.9996\nEpoch 82/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0208 - SimCLR_accuracy: 0.9995\nEpoch 83/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0217 - SimCLR_accuracy: 0.9995\nEpoch 84/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0213 - SimCLR_accuracy: 0.9995\nEpoch 85/100\n234/234 [==============================] - 148s 630ms/step - SimCLR_loss: 0.0215 - SimCLR_accuracy: 0.9994\nEpoch 86/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0206 - SimCLR_accuracy: 0.9995\nEpoch 87/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 0.0196 - SimCLR_accuracy: 0.9996\nEpoch 88/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0202 - SimCLR_accuracy: 0.9997\nEpoch 89/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0210 - SimCLR_accuracy: 0.9996\nEpoch 90/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 0.0206 - SimCLR_accuracy: 0.9996\nEpoch 91/100\n234/234 [==============================] - 148s 632ms/step - SimCLR_loss: 0.0201 - SimCLR_accuracy: 0.9996\nEpoch 92/100\n234/234 [==============================] - 151s 645ms/step - SimCLR_loss: 0.0205 - SimCLR_accuracy: 0.9995\nEpoch 93/100\n234/234 [==============================] - 148s 632ms/step - SimCLR_loss: 0.0200 - SimCLR_accuracy: 0.9996\nEpoch 94/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0196 - SimCLR_accuracy: 0.9997\nEpoch 95/100\n234/234 [==============================] - 148s 634ms/step - SimCLR_loss: 0.0206 - SimCLR_accuracy: 0.9996\nEpoch 96/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0190 - SimCLR_accuracy: 0.9997\nEpoch 97/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0204 - SimCLR_accuracy: 0.9996\nEpoch 98/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 0.0197 - SimCLR_accuracy: 0.9996\nEpoch 99/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 0.0193 - SimCLR_accuracy: 0.9996\nEpoch 100/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 0.0197 - SimCLR_accuracy: 0.9996\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fab2dab3dd8>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "BATCH_SIZE = 256 \n",
    "EPOCHS = 100     \n",
    "LEARNING_RATE = 0.0001\n",
    "SAVE_DIRECTORY = './cifar_10_experiment'\n",
    "\n",
    "sim_clr_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "\n",
    "dataset = get_unsupervised_dataset(batch_size=BATCH_SIZE)  \n",
    "dataset = dataset.take(len(dataset)-1)\n",
    "\n",
    "sim_clr_model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = sim_clr_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder.save_weights(f'{SAVE_DIRECTORY}/encoder_weights/ckpt1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/3\n234/234 [==============================] - 149s 622ms/step - SimCLR_loss: 0.0189 - SimCLR_accuracy: 0.9997\nEpoch 2/3\n234/234 [==============================] - 145s 621ms/step - SimCLR_loss: 0.0190 - SimCLR_accuracy: 0.9997\nEpoch 3/3\n234/234 [==============================] - 148s 631ms/step - SimCLR_loss: 0.0199 - SimCLR_accuracy: 0.9994\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7faa68571978>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "BATCH_SIZE = 256 \n",
    "EPOCHS = 3     \n",
    "LEARNING_RATE = 0.0001\n",
    "SAVE_DIRECTORY = './cifar_10_experiment'\n",
    "\n",
    "sim_clr_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "\n",
    "dataset = get_unsupervised_dataset(batch_size=BATCH_SIZE)  \n",
    "dataset = dataset.take(len(dataset)-1)\n",
    "\n",
    "sim_clr_model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7faae8ef0748>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "SAVE_DIRECTORY = './cifar_10_experiment'\n",
    "encoder = get_encoder()\n",
    "encoder(next(iter(dataset)))\n",
    "encoder.load_weights(f'{SAVE_DIRECTORY}/encoder_weights/ckpt1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_26\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_20 (Conv2D)           (256, 32, 32, 64)         1728      \n_________________________________________________________________\nbatch_normalization_20 (Batc (256, 32, 32, 64)         256       \n_________________________________________________________________\nsequential_16 (Sequential)   (256, 32, 32, 64)         148480    \n_________________________________________________________________\nsequential_19 (Sequential)   (256, 16, 16, 128)        526848    \n_________________________________________________________________\nsequential_22 (Sequential)   (256, 8, 8, 256)          2102272   \n_________________________________________________________________\nsequential_25 (Sequential)   (256, 4, 4, 512)          8398848   \n_________________________________________________________________\nflatten_1 (Flatten)          (256, 8192)               0         \n=================================================================\nTotal params: 11,178,432\nTrainable params: 11,168,832\nNon-trainable params: 9,600\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n234/234 [==============================] - 151s 630ms/step - SimCLR_loss: 5.3439 - SimCLR_accuracy: 0.9990\nEpoch 2/100\n234/234 [==============================] - 150s 640ms/step - SimCLR_loss: 5.3352 - SimCLR_accuracy: 0.9981\nEpoch 3/100\n234/234 [==============================] - 149s 638ms/step - SimCLR_loss: 5.3323 - SimCLR_accuracy: 0.9976\nEpoch 4/100\n234/234 [==============================] - 148s 632ms/step - SimCLR_loss: 5.3303 - SimCLR_accuracy: 0.9971\nEpoch 5/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 5.3295 - SimCLR_accuracy: 0.9964\nEpoch 6/100\n234/234 [==============================] - 149s 637ms/step - SimCLR_loss: 5.3271 - SimCLR_accuracy: 0.9965\nEpoch 7/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3259 - SimCLR_accuracy: 0.9964\nEpoch 8/100\n234/234 [==============================] - 151s 645ms/step - SimCLR_loss: 5.3253 - SimCLR_accuracy: 0.9962\nEpoch 9/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 5.3247 - SimCLR_accuracy: 0.9961\nEpoch 10/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 5.3236 - SimCLR_accuracy: 0.9955\nEpoch 11/100\n234/234 [==============================] - 148s 634ms/step - SimCLR_loss: 5.3226 - SimCLR_accuracy: 0.9956\nEpoch 12/100\n234/234 [==============================] - 149s 638ms/step - SimCLR_loss: 5.3226 - SimCLR_accuracy: 0.9953\nEpoch 13/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3220 - SimCLR_accuracy: 0.9950\nEpoch 14/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3207 - SimCLR_accuracy: 0.9949\nEpoch 15/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 5.3204 - SimCLR_accuracy: 0.9950\nEpoch 16/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3198 - SimCLR_accuracy: 0.9945\nEpoch 17/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 5.3192 - SimCLR_accuracy: 0.9949\nEpoch 18/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3189 - SimCLR_accuracy: 0.9947\nEpoch 19/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3187 - SimCLR_accuracy: 0.9944\nEpoch 20/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 5.3180 - SimCLR_accuracy: 0.9943\nEpoch 21/100\n234/234 [==============================] - 149s 637ms/step - SimCLR_loss: 5.3172 - SimCLR_accuracy: 0.9946\nEpoch 22/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 5.3171 - SimCLR_accuracy: 0.9940\nEpoch 23/100\n234/234 [==============================] - 149s 637ms/step - SimCLR_loss: 5.3166 - SimCLR_accuracy: 0.9941\nEpoch 24/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3162 - SimCLR_accuracy: 0.9940\nEpoch 25/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3161 - SimCLR_accuracy: 0.9941\nEpoch 26/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3155 - SimCLR_accuracy: 0.9943\nEpoch 27/100\n234/234 [==============================] - 149s 638ms/step - SimCLR_loss: 5.3150 - SimCLR_accuracy: 0.9942\nEpoch 28/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3145 - SimCLR_accuracy: 0.9943\nEpoch 29/100\n234/234 [==============================] - 149s 638ms/step - SimCLR_loss: 5.3143 - SimCLR_accuracy: 0.9938\nEpoch 30/100\n234/234 [==============================] - 148s 631ms/step - SimCLR_loss: 5.3145 - SimCLR_accuracy: 0.9940\nEpoch 31/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3141 - SimCLR_accuracy: 0.9933\nEpoch 32/100\n234/234 [==============================] - 149s 635ms/step - SimCLR_loss: 5.3137 - SimCLR_accuracy: 0.9936\nEpoch 33/100\n234/234 [==============================] - 148s 631ms/step - SimCLR_loss: 5.3131 - SimCLR_accuracy: 0.9939\nEpoch 34/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 5.3127 - SimCLR_accuracy: 0.9944\nEpoch 35/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 5.3124 - SimCLR_accuracy: 0.9943\nEpoch 36/100\n234/234 [==============================] - 149s 637ms/step - SimCLR_loss: 5.3122 - SimCLR_accuracy: 0.9943\nEpoch 37/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 5.3121 - SimCLR_accuracy: 0.9936\nEpoch 38/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3113 - SimCLR_accuracy: 0.9938\nEpoch 39/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3115 - SimCLR_accuracy: 0.9940\nEpoch 40/100\n234/234 [==============================] - 150s 640ms/step - SimCLR_loss: 5.3114 - SimCLR_accuracy: 0.9934\nEpoch 41/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3109 - SimCLR_accuracy: 0.9938\nEpoch 42/100\n234/234 [==============================] - 148s 630ms/step - SimCLR_loss: 5.3113 - SimCLR_accuracy: 0.9933\nEpoch 43/100\n234/234 [==============================] - 150s 643ms/step - SimCLR_loss: 5.3100 - SimCLR_accuracy: 0.9940\nEpoch 44/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 5.3100 - SimCLR_accuracy: 0.9935\nEpoch 45/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 5.3097 - SimCLR_accuracy: 0.9943\nEpoch 46/100\n234/234 [==============================] - 148s 630ms/step - SimCLR_loss: 5.3094 - SimCLR_accuracy: 0.9937\nEpoch 47/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3092 - SimCLR_accuracy: 0.9935\nEpoch 48/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 5.3092 - SimCLR_accuracy: 0.9941\nEpoch 49/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3089 - SimCLR_accuracy: 0.9935\nEpoch 50/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3084 - SimCLR_accuracy: 0.9931\nEpoch 51/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3086 - SimCLR_accuracy: 0.9939\nEpoch 52/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3083 - SimCLR_accuracy: 0.9934\nEpoch 53/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3080 - SimCLR_accuracy: 0.9934\nEpoch 54/100\n234/234 [==============================] - 149s 638ms/step - SimCLR_loss: 5.3078 - SimCLR_accuracy: 0.9929\nEpoch 55/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 5.3074 - SimCLR_accuracy: 0.9938\nEpoch 56/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 5.3069 - SimCLR_accuracy: 0.9940\nEpoch 57/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 5.3072 - SimCLR_accuracy: 0.9929\nEpoch 58/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3065 - SimCLR_accuracy: 0.9932\nEpoch 59/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3066 - SimCLR_accuracy: 0.9933\nEpoch 60/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 5.3061 - SimCLR_accuracy: 0.9938\nEpoch 61/100\n234/234 [==============================] - 148s 633ms/step - SimCLR_loss: 5.3065 - SimCLR_accuracy: 0.9934\nEpoch 62/100\n234/234 [==============================] - 147s 627ms/step - SimCLR_loss: 5.3062 - SimCLR_accuracy: 0.9934\nEpoch 63/100\n234/234 [==============================] - 147s 630ms/step - SimCLR_loss: 5.3054 - SimCLR_accuracy: 0.9940\nEpoch 64/100\n234/234 [==============================] - 148s 633ms/step - SimCLR_loss: 5.3050 - SimCLR_accuracy: 0.9938\nEpoch 65/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3055 - SimCLR_accuracy: 0.9937\nEpoch 66/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3047 - SimCLR_accuracy: 0.9939\nEpoch 67/100\n234/234 [==============================] - 152s 648ms/step - SimCLR_loss: 5.3055 - SimCLR_accuracy: 0.9931\nEpoch 68/100\n234/234 [==============================] - 147s 629ms/step - SimCLR_loss: 5.3043 - SimCLR_accuracy: 0.9943\nEpoch 69/100\n234/234 [==============================] - 147s 628ms/step - SimCLR_loss: 5.3043 - SimCLR_accuracy: 0.9936\nEpoch 70/100\n234/234 [==============================] - 149s 636ms/step - SimCLR_loss: 5.3039 - SimCLR_accuracy: 0.9935\nEpoch 71/100\n234/234 [==============================] - 150s 641ms/step - SimCLR_loss: 5.3042 - SimCLR_accuracy: 0.9937\nEpoch 72/100\n234/234 [==============================] - 161s 687ms/step - SimCLR_loss: 5.3039 - SimCLR_accuracy: 0.9936\nEpoch 73/100\n 62/234 [======>.......................] - ETA: 2:02 - SimCLR_loss: 5.3037 - SimCLR_accuracy: 0.9927"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e4fc91fb70bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msim_clr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CISC867/viewmaker_reproduction/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sim_clr_model = SimCLR(encoder, augmentation, projection_head)\n",
    "BATCH_SIZE = 256 \n",
    "EPOCHS = 100     \n",
    "LEARNING_RATE = 0.0001\n",
    "SAVE_DIRECTORY = './cifar_10_experiment'\n",
    "\n",
    "sim_clr_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "\n",
    "dataset = get_unsupervised_dataset(batch_size=BATCH_SIZE)  \n",
    "dataset = dataset.take(len(dataset)-1)\n",
    "\n",
    "sim_clr_model.fit(dataset, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_clr_model.save_weights(f'{SAVE_DIRECTORY}/simclr_weights/ckpt1')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e408a2d422f08ada9bc5fb395ddea2cf1b39d559985be2430f6620bfcca087f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}