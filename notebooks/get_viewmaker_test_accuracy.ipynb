{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training viewmaker the second time and getting a 99.87% accuracy, we want to train the classifier for it and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from SimCLR_data_util import preprocess_for_train\n",
    "from resnet_small import ResNet18\n",
    "from tensorflow.keras.layers import Dense\n",
    "from SimCLR import SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cifar_10 import get_unsupervised_dataset\n",
    "dataset = get_unsupervised_dataset(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAugmentation(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self, x):\n",
    "        augment_image = lambda im: preprocess_for_train(im, 32, 32)\n",
    "        return tf.map_fn(augment_image, x)\n",
    "\n",
    "augmentation = MyAugmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "    model = ResNet18(10)\n",
    "    encoder = tf.keras.Sequential(model.layers[:-1])\n",
    "    return encoder\n",
    "\n",
    "encoder = get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection_head():\n",
    "\n",
    "    projection_head = tf.keras.Sequential([\n",
    "        Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Dense(256)\n",
    "    ])\n",
    "\n",
    "    return projection_head\n",
    "\n",
    "projection_head = get_projection_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_clr_model = SimCLR(encoder, augmentation, projection_head, temperature=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efb70905c50>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "SAVE_DIRECTORY = './cifar_10_experiment'\n",
    "sim_clr_model.load_weights(f'{SAVE_DIRECTORY}/simclr_weights/ckpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cifar_10 import get_supervised_dataset\n",
    "\n",
    "dataset = get_supervised_dataset()  \n",
    "test_x, test_y = dataset[1]\n",
    "train_x, train_y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = sim_clr_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic_regression import TrainClassifier\n",
    "\n",
    "classifier = TrainClassifier(10, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, initial_learning_rate):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # print('step.numpy is', step)\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            step = step.eval()\n",
    "        if tf.math.equal(step, 60) or tf.math.equal(step, 80):\n",
    "            self.initial_learning_rate = self.initial_learning_rate/10\n",
    "            return self.initial_learning_rate\n",
    "        return self.initial_learning_rate\n",
    "\n",
    "lr_schedule = MyLRSchedule(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n391/391 [==============================] - 13s 26ms/step - loss: 995092785528832.0000 - categorical_accuracy: 0.5236 - val_loss: 956363924570112.0000 - val_categorical_accuracy: 0.5538\nEpoch 2/100\n391/391 [==============================] - 9s 24ms/step - loss: 770882406449152.0000 - categorical_accuracy: 0.5944 - val_loss: 973601373159424.0000 - val_categorical_accuracy: 0.5666\nEpoch 3/100\n391/391 [==============================] - 9s 24ms/step - loss: 708932335042560.0000 - categorical_accuracy: 0.6234 - val_loss: 845714024300544.0000 - val_categorical_accuracy: 0.6040\nEpoch 4/100\n391/391 [==============================] - 9s 24ms/step - loss: 628455855095808.0000 - categorical_accuracy: 0.6479 - val_loss: 854440122777600.0000 - val_categorical_accuracy: 0.6034\nEpoch 5/100\n391/391 [==============================] - 9s 24ms/step - loss: 605489725440000.0000 - categorical_accuracy: 0.6594 - val_loss: 861042427035648.0000 - val_categorical_accuracy: 0.5964\nEpoch 6/100\n391/391 [==============================] - 9s 24ms/step - loss: 545955204038656.0000 - categorical_accuracy: 0.6765 - val_loss: 889880582291456.0000 - val_categorical_accuracy: 0.6010\nEpoch 7/100\n391/391 [==============================] - 9s 24ms/step - loss: 525878379413504.0000 - categorical_accuracy: 0.6825 - val_loss: 940932039966720.0000 - val_categorical_accuracy: 0.5942\nEpoch 8/100\n391/391 [==============================] - 9s 24ms/step - loss: 483925273083904.0000 - categorical_accuracy: 0.7003 - val_loss: 950721209958400.0000 - val_categorical_accuracy: 0.5978\nEpoch 9/100\n391/391 [==============================] - 9s 24ms/step - loss: 491164373352448.0000 - categorical_accuracy: 0.7002 - val_loss: 902296326111232.0000 - val_categorical_accuracy: 0.6116\nEpoch 10/100\n391/391 [==============================] - 9s 24ms/step - loss: 471813398200320.0000 - categorical_accuracy: 0.7089 - val_loss: 945510944866304.0000 - val_categorical_accuracy: 0.6034\nEpoch 11/100\n391/391 [==============================] - 9s 24ms/step - loss: 428521100935168.0000 - categorical_accuracy: 0.7219 - val_loss: 929188592746496.0000 - val_categorical_accuracy: 0.6044\nEpoch 12/100\n391/391 [==============================] - 9s 24ms/step - loss: 434058991501312.0000 - categorical_accuracy: 0.7218 - val_loss: 903025463918592.0000 - val_categorical_accuracy: 0.6214\nEpoch 13/100\n391/391 [==============================] - 9s 24ms/step - loss: 414895048753152.0000 - categorical_accuracy: 0.7295 - val_loss: 1001388872040448.0000 - val_categorical_accuracy: 0.5996\nEpoch 14/100\n391/391 [==============================] - 9s 24ms/step - loss: 394640855400448.0000 - categorical_accuracy: 0.7387 - val_loss: 993738729979904.0000 - val_categorical_accuracy: 0.6022\nEpoch 15/100\n391/391 [==============================] - 9s 24ms/step - loss: 387641870647296.0000 - categorical_accuracy: 0.7424 - val_loss: 882427136311296.0000 - val_categorical_accuracy: 0.6144\nEpoch 16/100\n391/391 [==============================] - 9s 24ms/step - loss: 379814896730112.0000 - categorical_accuracy: 0.7440 - val_loss: 1060775250624512.0000 - val_categorical_accuracy: 0.5878\nEpoch 17/100\n391/391 [==============================] - 9s 24ms/step - loss: 365055812042752.0000 - categorical_accuracy: 0.7520 - val_loss: 939734415179776.0000 - val_categorical_accuracy: 0.6144\nEpoch 18/100\n391/391 [==============================] - 9s 24ms/step - loss: 341869766639616.0000 - categorical_accuracy: 0.7579 - val_loss: 989439534825472.0000 - val_categorical_accuracy: 0.6082\nEpoch 19/100\n391/391 [==============================] - 9s 24ms/step - loss: 343019677024256.0000 - categorical_accuracy: 0.7601 - val_loss: 1027892309917696.0000 - val_categorical_accuracy: 0.6132\nEpoch 20/100\n391/391 [==============================] - 9s 24ms/step - loss: 329834060316672.0000 - categorical_accuracy: 0.7648 - val_loss: 963435386896384.0000 - val_categorical_accuracy: 0.6196\nEpoch 21/100\n391/391 [==============================] - 9s 24ms/step - loss: 316222704975872.0000 - categorical_accuracy: 0.7713 - val_loss: 964688175169536.0000 - val_categorical_accuracy: 0.6214\nEpoch 22/100\n391/391 [==============================] - 9s 24ms/step - loss: 299910754729984.0000 - categorical_accuracy: 0.7764 - val_loss: 985423471968256.0000 - val_categorical_accuracy: 0.6188\nEpoch 23/100\n391/391 [==============================] - 9s 23ms/step - loss: 297993387376640.0000 - categorical_accuracy: 0.7784 - val_loss: 997613058916352.0000 - val_categorical_accuracy: 0.6214\nEpoch 24/100\n391/391 [==============================] - 9s 23ms/step - loss: 295904556875776.0000 - categorical_accuracy: 0.7840 - val_loss: 1063357264166912.0000 - val_categorical_accuracy: 0.6030\nEpoch 25/100\n391/391 [==============================] - 9s 23ms/step - loss: 298200250449920.0000 - categorical_accuracy: 0.7812 - val_loss: 1073530028425216.0000 - val_categorical_accuracy: 0.6066\nEpoch 26/100\n391/391 [==============================] - 9s 23ms/step - loss: 301577436921856.0000 - categorical_accuracy: 0.7810 - val_loss: 1120152435294208.0000 - val_categorical_accuracy: 0.6054\nEpoch 27/100\n391/391 [==============================] - 9s 23ms/step - loss: 270010098384896.0000 - categorical_accuracy: 0.7935 - val_loss: 1017791083708416.0000 - val_categorical_accuracy: 0.6186\nEpoch 28/100\n391/391 [==============================] - 9s 23ms/step - loss: 273374383177728.0000 - categorical_accuracy: 0.7923 - val_loss: 1056621413269504.0000 - val_categorical_accuracy: 0.6180\nEpoch 29/100\n391/391 [==============================] - 9s 23ms/step - loss: 259821026672640.0000 - categorical_accuracy: 0.7974 - val_loss: 1055685311725568.0000 - val_categorical_accuracy: 0.6108\nEpoch 30/100\n391/391 [==============================] - 9s 23ms/step - loss: 259307090214912.0000 - categorical_accuracy: 0.7986 - val_loss: 1058896672194560.0000 - val_categorical_accuracy: 0.6120\nEpoch 31/100\n391/391 [==============================] - 9s 23ms/step - loss: 258288327327744.0000 - categorical_accuracy: 0.7979 - val_loss: 1075818239361024.0000 - val_categorical_accuracy: 0.6210\nEpoch 32/100\n391/391 [==============================] - 9s 22ms/step - loss: 258089399877632.0000 - categorical_accuracy: 0.7988 - val_loss: 1123173475024896.0000 - val_categorical_accuracy: 0.6118\nEpoch 33/100\n391/391 [==============================] - 9s 22ms/step - loss: 236625233707008.0000 - categorical_accuracy: 0.8088 - val_loss: 1033921907130368.0000 - val_categorical_accuracy: 0.6228\nEpoch 34/100\n391/391 [==============================] - 9s 23ms/step - loss: 239128612438016.0000 - categorical_accuracy: 0.8092 - val_loss: 1124822608248832.0000 - val_categorical_accuracy: 0.6114\nEpoch 35/100\n391/391 [==============================] - 9s 23ms/step - loss: 231413358002176.0000 - categorical_accuracy: 0.8126 - val_loss: 1127261814128640.0000 - val_categorical_accuracy: 0.6114\nEpoch 36/100\n391/391 [==============================] - 9s 23ms/step - loss: 237841984520192.0000 - categorical_accuracy: 0.8121 - val_loss: 1105207559716864.0000 - val_categorical_accuracy: 0.6154\nEpoch 37/100\n391/391 [==============================] - 9s 24ms/step - loss: 224080405987328.0000 - categorical_accuracy: 0.8145 - val_loss: 1175998015995904.0000 - val_categorical_accuracy: 0.6046\nEpoch 38/100\n391/391 [==============================] - 9s 23ms/step - loss: 214742677323776.0000 - categorical_accuracy: 0.8192 - val_loss: 1085081544294400.0000 - val_categorical_accuracy: 0.6212\nEpoch 39/100\n391/391 [==============================] - 9s 23ms/step - loss: 214483419004928.0000 - categorical_accuracy: 0.8211 - val_loss: 1138707096666112.0000 - val_categorical_accuracy: 0.6198\nEpoch 40/100\n391/391 [==============================] - 9s 23ms/step - loss: 218660291477504.0000 - categorical_accuracy: 0.8186 - val_loss: 1129860940431360.0000 - val_categorical_accuracy: 0.6238\nEpoch 41/100\n391/391 [==============================] - 9s 23ms/step - loss: 203958601646080.0000 - categorical_accuracy: 0.8245 - val_loss: 1103961348112384.0000 - val_categorical_accuracy: 0.6182\nEpoch 42/100\n391/391 [==============================] - 9s 23ms/step - loss: 208243032850432.0000 - categorical_accuracy: 0.8243 - val_loss: 1192645980323840.0000 - val_categorical_accuracy: 0.6118\nEpoch 43/100\n391/391 [==============================] - 9s 23ms/step - loss: 187772816064512.0000 - categorical_accuracy: 0.8345 - val_loss: 1123550693949440.0000 - val_categorical_accuracy: 0.6196\nEpoch 44/100\n391/391 [==============================] - 9s 23ms/step - loss: 194369063747584.0000 - categorical_accuracy: 0.8310 - val_loss: 1127996790407168.0000 - val_categorical_accuracy: 0.6192\nEpoch 45/100\n391/391 [==============================] - 9s 23ms/step - loss: 194980626825216.0000 - categorical_accuracy: 0.8330 - val_loss: 1156517252300800.0000 - val_categorical_accuracy: 0.6148\nEpoch 46/100\n391/391 [==============================] - 9s 23ms/step - loss: 190496479641600.0000 - categorical_accuracy: 0.8341 - val_loss: 1124795362050048.0000 - val_categorical_accuracy: 0.6304\nEpoch 47/100\n391/391 [==============================] - 9s 23ms/step - loss: 175063873617920.0000 - categorical_accuracy: 0.8421 - val_loss: 1110275218472960.0000 - val_categorical_accuracy: 0.6206\nEpoch 48/100\n391/391 [==============================] - 9s 23ms/step - loss: 185623788912640.0000 - categorical_accuracy: 0.8370 - val_loss: 1193065276506112.0000 - val_categorical_accuracy: 0.6204\nEpoch 49/100\n391/391 [==============================] - 9s 23ms/step - loss: 183553262354432.0000 - categorical_accuracy: 0.8384 - val_loss: 1176357316853760.0000 - val_categorical_accuracy: 0.6118\nEpoch 50/100\n391/391 [==============================] - 9s 23ms/step - loss: 168345085149184.0000 - categorical_accuracy: 0.8448 - val_loss: 1177102896332800.0000 - val_categorical_accuracy: 0.6114\nEpoch 51/100\n391/391 [==============================] - 9s 23ms/step - loss: 180015215935488.0000 - categorical_accuracy: 0.8405 - val_loss: 1159216907681792.0000 - val_categorical_accuracy: 0.6136\nEpoch 52/100\n391/391 [==============================] - 9s 23ms/step - loss: 164430306344960.0000 - categorical_accuracy: 0.8474 - val_loss: 1224047962619904.0000 - val_categorical_accuracy: 0.6086\nEpoch 53/100\n391/391 [==============================] - 9s 23ms/step - loss: 171103343345664.0000 - categorical_accuracy: 0.8439 - val_loss: 1223379155681280.0000 - val_categorical_accuracy: 0.6132\nEpoch 54/100\n391/391 [==============================] - 9s 23ms/step - loss: 158129287331840.0000 - categorical_accuracy: 0.8500 - val_loss: 1188000973193216.0000 - val_categorical_accuracy: 0.6202\nEpoch 55/100\n391/391 [==============================] - 9s 23ms/step - loss: 168970321657856.0000 - categorical_accuracy: 0.8477 - val_loss: 1210583777017856.0000 - val_categorical_accuracy: 0.6276\nEpoch 56/100\n391/391 [==============================] - 9s 23ms/step - loss: 161083117535232.0000 - categorical_accuracy: 0.8497 - val_loss: 1161469081157632.0000 - val_categorical_accuracy: 0.6260\nEpoch 57/100\n391/391 [==============================] - 9s 23ms/step - loss: 171911451508736.0000 - categorical_accuracy: 0.8429 - val_loss: 1249143859183616.0000 - val_categorical_accuracy: 0.6108\nEpoch 58/100\n391/391 [==============================] - 9s 23ms/step - loss: 155020284657664.0000 - categorical_accuracy: 0.8552 - val_loss: 1261270162472960.0000 - val_categorical_accuracy: 0.6002\nEpoch 59/100\n391/391 [==============================] - 9s 22ms/step - loss: 165799780155392.0000 - categorical_accuracy: 0.8484 - val_loss: 1193862798245888.0000 - val_categorical_accuracy: 0.6240\nEpoch 60/100\n391/391 [==============================] - 9s 23ms/step - loss: 150435759390720.0000 - categorical_accuracy: 0.8584 - val_loss: 1222062077116416.0000 - val_categorical_accuracy: 0.6176\nEpoch 61/100\n391/391 [==============================] - 9s 23ms/step - loss: 151340705644544.0000 - categorical_accuracy: 0.8569 - val_loss: 1191531436310528.0000 - val_categorical_accuracy: 0.6146\nEpoch 62/100\n391/391 [==============================] - 9s 23ms/step - loss: 139479239098368.0000 - categorical_accuracy: 0.8630 - val_loss: 1227502324285440.0000 - val_categorical_accuracy: 0.6110\nEpoch 63/100\n391/391 [==============================] - 9s 23ms/step - loss: 138535176765440.0000 - categorical_accuracy: 0.8653 - val_loss: 1263447174021120.0000 - val_categorical_accuracy: 0.6208\nEpoch 64/100\n391/391 [==============================] - 9s 23ms/step - loss: 153209519734784.0000 - categorical_accuracy: 0.8565 - val_loss: 1251259264794624.0000 - val_categorical_accuracy: 0.6168\nEpoch 65/100\n391/391 [==============================] - 9s 23ms/step - loss: 141870403420160.0000 - categorical_accuracy: 0.8610 - val_loss: 1304839787118592.0000 - val_categorical_accuracy: 0.6150\nEpoch 66/100\n391/391 [==============================] - 9s 23ms/step - loss: 140480687898624.0000 - categorical_accuracy: 0.8631 - val_loss: 1268934531612672.0000 - val_categorical_accuracy: 0.6152\nEpoch 67/100\n391/391 [==============================] - 9s 22ms/step - loss: 126256964173824.0000 - categorical_accuracy: 0.8715 - val_loss: 1247827317489664.0000 - val_categorical_accuracy: 0.6260\nEpoch 68/100\n391/391 [==============================] - 9s 23ms/step - loss: 133949821026304.0000 - categorical_accuracy: 0.8678 - val_loss: 1237059297607680.0000 - val_categorical_accuracy: 0.6222\nEpoch 69/100\n391/391 [==============================] - 9s 23ms/step - loss: 135926772662272.0000 - categorical_accuracy: 0.8666 - val_loss: 1310237621485568.0000 - val_categorical_accuracy: 0.6114\nEpoch 70/100\n391/391 [==============================] - 9s 23ms/step - loss: 121715153698816.0000 - categorical_accuracy: 0.8728 - val_loss: 1261978429423616.0000 - val_categorical_accuracy: 0.6172\nEpoch 71/100\n391/391 [==============================] - 9s 23ms/step - loss: 125370607075328.0000 - categorical_accuracy: 0.8718 - val_loss: 1284610356936704.0000 - val_categorical_accuracy: 0.6190\nEpoch 72/100\n391/391 [==============================] - 9s 23ms/step - loss: 120290625454080.0000 - categorical_accuracy: 0.8747 - val_loss: 1277000345976832.0000 - val_categorical_accuracy: 0.6088\nEpoch 73/100\n391/391 [==============================] - 9s 23ms/step - loss: 121242447249408.0000 - categorical_accuracy: 0.8750 - val_loss: 1250837418475520.0000 - val_categorical_accuracy: 0.6212\nEpoch 74/100\n391/391 [==============================] - 9s 23ms/step - loss: 141191479820288.0000 - categorical_accuracy: 0.8669 - val_loss: 1292264525529088.0000 - val_categorical_accuracy: 0.6206\nEpoch 75/100\n391/391 [==============================] - 9s 23ms/step - loss: 136677838290944.0000 - categorical_accuracy: 0.8699 - val_loss: 1246830079770624.0000 - val_categorical_accuracy: 0.6204\nEpoch 76/100\n391/391 [==============================] - 9s 23ms/step - loss: 122201743294464.0000 - categorical_accuracy: 0.8770 - val_loss: 1347492167811072.0000 - val_categorical_accuracy: 0.6104\nEpoch 77/100\n391/391 [==============================] - 9s 23ms/step - loss: 119495846789120.0000 - categorical_accuracy: 0.8754 - val_loss: 1280350017814528.0000 - val_categorical_accuracy: 0.6206\nEpoch 78/100\n391/391 [==============================] - 9s 23ms/step - loss: 105484598116352.0000 - categorical_accuracy: 0.8839 - val_loss: 1298726706479104.0000 - val_categorical_accuracy: 0.6174\nEpoch 79/100\n391/391 [==============================] - 9s 23ms/step - loss: 114776592089088.0000 - categorical_accuracy: 0.8792 - val_loss: 1261649998643200.0000 - val_categorical_accuracy: 0.6158\nEpoch 80/100\n391/391 [==============================] - 9s 23ms/step - loss: 110076220145664.0000 - categorical_accuracy: 0.8825 - val_loss: 1283560371650560.0000 - val_categorical_accuracy: 0.6168\nEpoch 81/100\n391/391 [==============================] - 9s 22ms/step - loss: 106204181299200.0000 - categorical_accuracy: 0.8844 - val_loss: 1301403007975424.0000 - val_categorical_accuracy: 0.6148\nEpoch 82/100\n391/391 [==============================] - 9s 23ms/step - loss: 109874901942272.0000 - categorical_accuracy: 0.8824 - val_loss: 1319006870962176.0000 - val_categorical_accuracy: 0.6164\nEpoch 83/100\n391/391 [==============================] - 9s 23ms/step - loss: 98490604584960.0000 - categorical_accuracy: 0.8903 - val_loss: 1303779198631936.0000 - val_categorical_accuracy: 0.6100\nEpoch 84/100\n391/391 [==============================] - 9s 23ms/step - loss: 92237828456448.0000 - categorical_accuracy: 0.8941 - val_loss: 1273621280456704.0000 - val_categorical_accuracy: 0.6202\nEpoch 85/100\n391/391 [==============================] - 9s 22ms/step - loss: 101091341500416.0000 - categorical_accuracy: 0.8883 - val_loss: 1328183068590080.0000 - val_categorical_accuracy: 0.6096\nEpoch 86/100\n391/391 [==============================] - 9s 22ms/step - loss: 93668706877440.0000 - categorical_accuracy: 0.8934 - val_loss: 1296594389434368.0000 - val_categorical_accuracy: 0.6140\nEpoch 87/100\n391/391 [==============================] - 9s 22ms/step - loss: 109348248354816.0000 - categorical_accuracy: 0.8848 - val_loss: 1351859881115648.0000 - val_categorical_accuracy: 0.6126\nEpoch 88/100\n391/391 [==============================] - 9s 23ms/step - loss: 98971355709440.0000 - categorical_accuracy: 0.8908 - val_loss: 1359034087112704.0000 - val_categorical_accuracy: 0.6164\nEpoch 89/100\n391/391 [==============================] - 9s 22ms/step - loss: 91231153553408.0000 - categorical_accuracy: 0.8943 - val_loss: 1316394859757568.0000 - val_categorical_accuracy: 0.6194\nEpoch 90/100\n391/391 [==============================] - 9s 23ms/step - loss: 104838490750976.0000 - categorical_accuracy: 0.8860 - val_loss: 1332013105676288.0000 - val_categorical_accuracy: 0.6172\nEpoch 91/100\n391/391 [==============================] - 9s 23ms/step - loss: 99469186039808.0000 - categorical_accuracy: 0.8894 - val_loss: 1358942550622208.0000 - val_categorical_accuracy: 0.6088\nEpoch 92/100\n391/391 [==============================] - 9s 23ms/step - loss: 92021880520704.0000 - categorical_accuracy: 0.8959 - val_loss: 1353840666345472.0000 - val_categorical_accuracy: 0.6146\nEpoch 93/100\n391/391 [==============================] - 9s 22ms/step - loss: 90933458632704.0000 - categorical_accuracy: 0.8940 - val_loss: 1332979339100160.0000 - val_categorical_accuracy: 0.6166\nEpoch 94/100\n391/391 [==============================] - 9s 24ms/step - loss: 87925555462144.0000 - categorical_accuracy: 0.8973 - val_loss: 1342317537525760.0000 - val_categorical_accuracy: 0.6214\nEpoch 95/100\n391/391 [==============================] - 9s 23ms/step - loss: 87994123943936.0000 - categorical_accuracy: 0.8985 - val_loss: 1342417261297664.0000 - val_categorical_accuracy: 0.6206\nEpoch 96/100\n391/391 [==============================] - 9s 23ms/step - loss: 88662956048384.0000 - categorical_accuracy: 0.8970 - val_loss: 1375685138448384.0000 - val_categorical_accuracy: 0.6088\nEpoch 97/100\n391/391 [==============================] - 9s 23ms/step - loss: 94659703472128.0000 - categorical_accuracy: 0.8943 - val_loss: 1380203980914688.0000 - val_categorical_accuracy: 0.6132\nEpoch 98/100\n391/391 [==============================] - 9s 23ms/step - loss: 93372169584640.0000 - categorical_accuracy: 0.8955 - val_loss: 1347221853306880.0000 - val_categorical_accuracy: 0.6122\nEpoch 99/100\n391/391 [==============================] - 9s 23ms/step - loss: 84575254478848.0000 - categorical_accuracy: 0.8996 - val_loss: 1392785550737408.0000 - val_categorical_accuracy: 0.6122\nEpoch 100/100\n391/391 [==============================] - 9s 22ms/step - loss: 87380857978880.0000 - categorical_accuracy: 0.8986 - val_loss: 1377157506924544.0000 - val_categorical_accuracy: 0.6104\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7efb69812898>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "classifier.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), \n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                    #loss=tf.keras.losses.categorical_crossentropy,\n",
    "                    metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "x = tf.convert_to_tensor(dataset[0][0])\n",
    "y = dataset[0][1]\n",
    "x_val = tf.convert_to_tensor(dataset[1][0][:5000])\n",
    "y_val = dataset[1][1][:5000]\n",
    "classifier.fit(x=x, y=y, validation_data=(x_val, y_val), batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}